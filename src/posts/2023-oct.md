---
title: International PauseAI protest 21st October 2023
description: We are organizing an international protest to demand a pause on dangerous AI development.
---

## October 21st (Saturday), in multiple countries

- US, California, San Francisco ([Sign up](https://www.mixily.com/event/5206622392930519518))
- UK, Parliament Square, London ([Sign up](https://www.mixily.com/event/4774799330762010477), [facebook](https://www.facebook.com/events/644748401084077))
- Israel, Jerusalem ([Sign up](https://www.mixily.com/event/2216232092023925957))
- Belgium, Brussels ([Sign up](https://www.mixily.com/event/2708675063120711075))
- Netherlands, Den Haag ([Sign up](https://www.mixily.com/event/8536294863402363208))
- Italy ([Sign up](https://www.mixily.com/event/7782058162912076825))
- Germany ([Sign up](https://www.mixily.com/event/873099107580787879))
- Your country here? [Discuss on discord!](https://discord.gg/anXWYCCdH5)

## Why we protest

AI is rapidly becoming more powerful, far faster than virtually any AI scientist has predicted.
Billions are being poured into AI capabilities, and the results are staggering.
New models are [outperforming humans](/sota) in a lot of domains.
As capabilities increase, so do the [risks](/risks).
Scientists are even [warning](https://www.safe.ai/statement-on-ai-risk) that AI might [end up destroying humanity](/xrisk).

Our politicians are not taking this topic remotely as seriously as they should.
We need our leaders to listen to these warnings.
We need them to take action to stop this suicide race.

But this can realistically only happen on an international level, because the competitive pressures are too much to do this nationally.
On November 1st and 2nd, the very first AI Safety Summit will be held in the UK.
The perfect opportunity to set the first steps towards sensible international AI safety regulation.
We've been asking for a summit ever since our very first protest, so we're glad this is happening.
But as of today, not a single country has drafted any form of proposal on how to mitigate the risks we're facing.

## What we ask

- **Policy makers**: Focus on pre-training regulations. We cannot allow companies to train potentially world-ending AI models. Writing legislation is hard, and it takes time, but we may not have that long.
- **Companies**: Be vocal about supporting a pause in principle. If you sign statements that this technology could kill us all, show the world that you'd prefer not to build it if it was a viable option.
- **Summit invitees**: Prioritize safety over economic growth. We know AI can make your country richer, but that's not why you're summoned here. Be the adult in the room.

For our entire proposal, see [here](/proposal).
