---
title: AI Safety Summit
description: What it would take to organize a summit on AI safety.
---

_Update June 7th, 2023: UK is hosting an AI safety summit in autumn 2023._

AI presents very real risks to humanity, including the [risk of extinction](/xrisk).
Progress in AI capabilities is accelerating at a [frantic pace](/urgency), and we are not prepared for the consequences.
AI companies are locked in a race to the bottom, where safety is not the highest priority.
We need governments to step in and regulate AI development.
This needs to happen on an international level.
**The only way to achieve this is through a summit.**
The primary goal of PauseAI is to convince one government to organize such a summit.

But what does such a summit look like?
Well, it will be a meeting of national governments, hosted by one of them.
A summit can take many days and will be attended by many people.
Organizing it is a monumental task, and we are not experts in this field.

The goal of the Summit itself is a _treaty_, which is a formal agreement between two or more states in reference to peace, alliance, commerce, or other international relations.
In our case, the AI Safety Treaty should be an agreement between the participating states to pause AI development until the risks are better understood.

## Organizing a summit

One government will have to take the lead in organizing the summit.
This government will be the host of the summit and will be responsible for the logistics.
They need to find a suitable date and location, arrange the catering, draft the agenda, and invite the other governments.

## Examples of Summits and resulting treaties

- **Montreal Protocol** (1987): The Montreal Protocol is an international environmental treaty designed to protect the ozone layer by phasing out the production and consumption of ozone-depleting substances. It has been highly successful in reducing the use of substances like chlorofluorocarbons (CFCs) and has contributed to the gradual recovery of the ozone layer.
- **Stockholm Convention on Persistent Organic Pollutants** (2001): The Stockholm Convention is an international treaty aimed at protecting human health and the environment from persistent organic pollutants (POPs). These are toxic chemicals that persist in the environment, bioaccumulate in living organisms, and can have serious adverse effects on human health and ecosystems. Scientists raised concerns about the harmful effects of POPs, including their ability to travel long distances through air and water currents. The convention led to the banning or severe restrictions on the production and use of several POPs, including polychlorinated biphenyls (PCBs), dichlorodiphenyltrichloroethane (DDT), and dioxins.

## Suggested educational agenda

Many people will be attending the summit, and not all of them will be deeply familiar with AI safety.
They must be able to follow the discussions and make informed decisions.
Therefore, we believe it is paramount to make education on x-risk a part of the Summit.

One particularly interesting (yet unconventional) approach, is to require attendees to [learn](/learn) about AI safety before attending the summit.
Additionally, the summit itself should include a few days of education on AI safety and policy.

The following is a suggested agenda for the summit:

- **Introduction to Artificial Intelligence**. Without understanding the basics of AI, it is almost impossible to understand the risks.
  - Neural networks.
  - Large language models.
  - Market dynamics of AI
- **AI safety**. The difficulty of the alignment problem is not obvious. Understanding the core challenges of the field is necessary to understand the urgency of the situation.
  - What is a Superintelligence
  - The alignment problem
  - Instrumental convergence
  - Orthogonality thesis
- **AI safety policy**. Governing the complex field of AI safety is not easy. We need to understand the challenges and opportunities of AI safety policy.
  - International level
  - Funding AI safety research
  - Risks of AI research publications
  - Governance of open source models
- **Negotiation of the treaty**. See [our proposal](/proposal) for concrete suggestions on the contents of the treaty.

## Who should organize the summit?

The most important thing is that _any government_ organizes the summit as fast as possible.
[We may not have much time left](/urgency).
However, some countries are better suited than others.

One likely candidate is the **United Kingdom**.
The UK has a long history of leading the world in international cooperation.
They are also a member of the UN Security Council, which gives them a lot of influence.
The UK is also a world leader in AI research, and AI safety research specifically.
Even more importantly, Prime Minister Rishi Sunak has already discussed and acknowledged existential risk of AI systems and has stated that [the UK is in a well-placed position to lead the global collaboration on safe AI development](https://twitter.com/RishiSunak/status/1662369922234679297).
He will also [talk about this at the G7](https://twitter.com/RishiSunak/status/1663838958558539776).

A different candidate is the **United States**.
As the world's largest economy and military power, the US has a lot of influence.
They are also the home to most of the leading AI companies.

The **European Union** is another candidate.
They have already written AI legislation (the AI ACT), although this document does not yet address the existential risks of AI.
