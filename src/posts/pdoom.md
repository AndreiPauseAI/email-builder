---
title: List of p(doom) values
description: How likely do AI various researchers believe AI will cause human extinction?
---

What is p(doom)?
The probability of very bad outcomes (e.g. human extinction) as a result of AI.
This most often refers mainly to the chance that [AI takes over](/ai-takeover) from humanity, but there are different scenarios that also constitute as "doom".
For example, a large portion of the population dying due to a novel biological weapon created by AI, social callapse due to a large-scale cyberattack, or AI causing a nuclear war.
Note that not everyone is using the same definition when talking about their p(doom) values.
Most notably the time horizon is often not specified, which makes comparing a bit difficult.

### p(doom) numbers, from low to high

- Yann LeCun (Meta Chief Scientist): [less than 0.01%](https://twitter.com/liron/status/1736555643384025428)
- Vitalik Buterin: [10%](https://x.com/liron/status/1729740226594258982?s=20)
- Geoff Hinton (one of three godfathers of AI): [10%](https://twitter.com/geoffreyhinton/status/1719447980753719543) chance of extinction in next 30 years if unregulated
- Lina Khan (head of FTC), Nov 2023: [15%](https://twitter.com/liron/status/1723458202090774949)
- Paul Christiano (former alignment lead at OpenAI, current researcher at ARC) [10-20%](https://www.youtube.com/watch?v=GyFkWb903aU&t=560s) chance of AI takeover, many/most humans dead. Cumulative risks go to 50% when you get to human-level AI
- Dario Amodei (CEO of Anthropic): [10-25%](https://twitter.com/liron/status/1710520914444718459) combining something wrong with model plus human misuse
- Elon Musk: [20-30%](https://www.youtube.com/watch?v=57y7DxWfOS0&t=50s)
- Emmet Shear [5-50%](https://www.youtube.com/watch?v=9oUbauum4uI)
- AI Safety Researchers (average): [30%](https://web.archive.org/web/20221013014859/https://www.alignmentforum.org/posts/QvwSr5LsxyDeaPK5s/existential-risk-from-ai-survey-results)
- Scott Alexander: [33%](https://astralcodexten.substack.com/p/why-i-am-not-as-much-of-a-doomer)
- Eli Lifland (Top competitive forecaster): [35%](https://forum.effectivealtruism.org/posts/QeLE22fefLqKfYTW6/eli-lifland-on-navigating-the-ai-alignment-landscape)
- Average AI engineer: [40%](https://twitter.com/AISafetyMemes/status/1713515843194077583)
- Holden Karnofsky: [50%](https://www.cold-takes.com/where-ai-forecasting-stands-today/)
- Jan Leike (alignment lead at OpenAI), Aug 2023: [10-90%](https://www.youtube.com/watch?v=ZP_N4q5U3eE&t=1h16m)
- The median machine learning researcher: 5-10% (but in spring 2022, before progress sped up!)
- Zvi Mowshowitz: [60%](https://x.com/liron/status/1729274710670893262?s=20)
- Dan Hendrycks: [>80%](https://twitter.com/DanHendrycks/status/1642394635657162753)
- Eliezer >95%
